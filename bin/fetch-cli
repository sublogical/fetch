#! /usr/bin/ruby
#--
# Copyright (c) 2010 by Whitepages, Inc. All Rights Reserved.
#
# File name: fetch-cli
# Author:    Jay Hoover
# Date:      12/22/2009
#++
#
# === File Description
# Submit a job to the crawler engine for processing or check on output status
#
# Usage:
#
#  fetch-cli submit <type> <url>
#  fetch-cli submit <type> -f <filepath>
#  fetch-cli status <crawl-id>
#  fetch-cli view <url>
#  fetch-cli output <url>

require 'optparse'
require 'rubygems'
$: << File.expand_path(File.join(File.dirname(__FILE__), "../lib"))
require 'fetch'


$options = {
  :host => 'localhost',
  :port => 6379,
  :verbose => false
}

$script_name = File.basename($0)


# === Description
# Standard options shared by all configurations
#
def do_standard_opts(opts)
  opts.on("-h", "--host=host",
          "Default: #{$options[:host]}") { |$options[:host]| }
  
  opts.on("-p", "--port=port",
          "Default: #{$options[:port]}") { |$options[:port]| }
  
  opts.on("-v", "--verbose",
          "Default: #{$options[:verbose]}") { |$options[:verbose]| }
  
  opts.on("-h", "--help",
          "Show this help message.") { puts opts; exit }
end

# === Description
# Create a fetch client based on command line configuration
#
def create_client
  Fetch::Client.new(:host => $options[:host],
                    :port => $options[:port])
end

# === Description
# Command to submit a job to the crawler
#
def do_submit
  urls = []
  fetch_type = nil

  opts = ARGV.options do |opts|
      opts.banner = %Q!
Usage: 
  #{$script_name} submit [options]

Description: 
  Submit a job to the crawler for processing. Jobs should consist of a type
  and a URL.

Details:
!
    opts.on("-f", String,
            "The file containing URLs to add to a crawl",
            "Default: none") { |$options[:file]| }
      
    opts.on("-i", String,
            "The ID for the crawl to add URLs to",
            "Default: none") { |$options[:crawl]| }

    do_standard_opts(opts)

    opts.parse!

    fetch_type = ARGV.shift
    if fetch_type.nil?
      puts "Error: type not specified"
      puts opts
    end
    
    if $options[:file]
      puts "not implemented"
      exit
    else
      if ARGV.length == 0
        puts "Error: url not specified"
        puts opts
      end
      urls = ARGV.clone
    end
  end

  $options[:crawl] ||= Fetch.create_crawl_id
  
  client = create_client
  client.submit_urls($options[:crawl], fetch_type, urls)
end

# === Description
# Command to dump the cached data for a URL
#
def do_view
  puts "View: not implemented"
end

# === Description
# Command to dump the current status of a crawl
#
def do_status
  crawl_id = nil
  
  opts = ARGV.options do |opts|
      opts.banner = %Q!
Usage: 
  #{$script_name} list [options]

Description: 
  List the currently active crawl tasks

Details:
!
    do_standard_opts(opts)

    opts.parse!

    crawl_id = ARGV.shift
    if crawl_id.nil?
      puts "Error: no crawl_id specified"
      puts opts
      exit
    end
    
  end

  client = create_client
  output = client.status(crawl_id)

  puts "Crawl: #{crawl_id}"
  puts "  Pending Jobs: #{output[:count]}"
  output[:jobs].each do |job|
    puts "  #{job.describe}"
  end
end

# === Description
# Command to list the the currently active crawls
#
def do_list
  opts = ARGV.options do |opts|
      opts.banner = %Q!
Usage: 
  #{$script_name} list [options]

Description: 
  List the currently active crawl tasks

Details:
!
    do_standard_opts(opts)

    opts.parse!
  end
  client = create_client

  crawls = client.list
  puts "Found #{crawls.count} crawls"
  crawls.each { |crawl| puts "  #{crawl}" }
end

# === Description
# Command to reset one or all crawls
#
def do_reset
  crawl_ids = nil
  
  opts = ARGV.options do |opts|
      opts.banner = %Q!
Usage: 
  #{$script_name} reset <crawl id> [options]

Description: 
  Resets the crawlers listed

Details:
!
    do_standard_opts(opts)

    opts.parse!

    crawl_ids = ARGV.clone    
  end
  client = create_client

  count = client.reset(crawl_ids)
  puts "Reset #{count} crawls"
end

def do_output
  puts "Output: not implemented"
end

def do_peek
  crawl_ids = nil
  
  opts = ARGV.options do |opts|
      opts.banner = %Q!
Usage: 
  #{$script_name} reset <crawl id> [options]

Description: 
  Resets the crawlers listed

Details:
!
    do_standard_opts(opts)

    opts.parse!

    crawl_ids = ARGV.clone    
  end
  client = create_client

  crawl_ids.each do |crawl_id|
    output = client.status(crawl_id, 0, 0)
    puts "Crawl: #{crawl_id}"
    puts "  Pending Jobs: #{output[:count]}"
    output[:jobs].each do |job|
      puts "  #{job.describe}"
    end
  end
end

def do_default
  ARGV.options do |opts|
      opts.banner = %Q!
Usage: 
  #{$script_name} [command] [options]

Description: 
  This script is used to blah blah blah blah

Commands:
  submit - Submit URLs or other seed information to a crawler.
  view   - View the crawled URL
  status - Check the status of a crawl
  list   - List currently active crawls
  reset  - Reset one or more crawlers
  output - Download the output from a crawl
  peek   - Dump information on the next job to be performed for a crawl

Details:
!
    do_standard_opts(opts)

    puts opts
  end
  exit
end    

cmd = ARGV.shift
case cmd
when 'submit'
  do_submit
when 'view'
  do_view
when 'status'
  do_status
when 'list'
  do_list
when 'reset'
  do_reset
when 'output'
  do_output
when 'peek'
  do_peek
else
  do_default
end

